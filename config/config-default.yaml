##################################################################
#                          General                               #
##################################################################

general:
    # List of characters to include in our dataset (the phrase CAN NOT use characters that are not defined here).
    # Separate each character with a comma with no ending comma present
    characters: A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z

    # Code has two modes, training and test. 'train' trains the model and saves the best model as defined by
    # criterias. 'test' runs the set suit and gives the final accuracy of the model.
    mode: train

    # Turn debug mode on/off
    debug: false


##################################################################
#                          Logging                               #
##################################################################

logging:
    batch_reporting: 10


##################################################################
#                          Various                               #
##################################################################

various:
    # Indicate if we should start tensorboard
    tensorboard: false

    # Save model only if save indicator is present. This is useful early in training as the
    # system will use a LOT time saving models every single epoch. Running the TF based attention
    # model, training and validating on a dataset of size 10k and 1k takes about 5 seconds on the GPU,
    # while storing the model takes about 30 seconds. Turning this indicator on does not actually save
    # the weights unless you have a file named 'save' in your output directory under the current uid.
    # Note: This functioality is only implemented for the TF callbacks.
    save-indicator: false


##################################################################
#                           Path                                 #
##################################################################

path:
    # Where to save all the images
    image: PROJECT_ROOT_SEP_data_SEP_image

    # Where to save the data (pickle files and session dumps)
    data: PROJECT_ROOT_SEP_data_SEP_data

    # Where to save the output (logs and images)
    output: PROJECT_ROOT_SEP_data_SEP_output


##################################################################
#                         Word list                              #
##################################################################

wordlist:
    # Set to true to remove duplicates within the same set
    remove-duplicate-set: true

    # Set to true to remove duplicates across all sets
    remove-duplicate-all: false


##################################################################
#                       Transformation                           #
##################################################################

transformation:
    # If noise handler is called, use this degree of randomness (in percent)
    noise-random-factor: 0

    # Seed to use for randomness
    noise-random-seed: None

##################################################################
#                       Preprocessing                            #
##################################################################

preprocessing:
    run: true

    # Remove all earlier data on each run
    wipe: true

    # Saves
    save:
        # The entire canvas (as defined in this config file)
        canvas: true

        # The cropped images
        cropped: true

        # The signatures
        signatures: true

    # Settings for text
    text:
        fonts:
        - arial-mono
        size: 35

    # Settings for the canvas we write on (should be irrelevant)
    canvas:
        width: 500
        height: 50

    # The signature stuff
    signature:
        height: 1
        position: 14

    # Various settings for the input
    input:
        # Maximum length of a word to classify
        max-length: 10

    # Training set
    training-set:
        size: 30

    # Validate set
    validate-set:
        size: 20

    # Test set
    test-set:
        size: 20


##################################################################
#                         Predicting                             #
##################################################################

predicting:
    run: true

    # How many epochs to run
    epochs: 10

    # Size of each batch. NOTE: This value must divide the size of training, validation and test sets
    batch-size: 10

    # The learning rate for our network
    learning-rate: 0.001

    # Evaluating best model to save weights for. With a value of 5 we will store the model if the results are the best
    # we've seen the past 5 epochs. We evaluate this based on validation loss.
    best-results: 5

    # Class to lazy load for the prediction
    predictor: prediction.tensorflow.networks.sequence.EmbeddingRNNSeq2SeqPredictor
